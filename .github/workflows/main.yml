name: Process Text
on:
  workflow_dispatch:
    inputs:
      text:
        description: 'Text to analyze (URL or plain text)'
        required: true
        type: string

jobs:
  analyze:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      # ðŸ”¹ Generar requirements.txt si no existe
      - name: Create requirements.txt
        run: |
          echo "transformers" > requirements.txt
          echo "torch" >> requirements.txt
          echo "numpy" >> requirements.txt
          echo "tensorflow-cpu" >> requirements.txt
          echo "newspaper3k" >> requirements.txt  # AÃ±adimos newspaper3k para procesar URLs

      # ðŸ”¹ Cachear dependencias basÃ¡ndose en `requirements.txt`
      - name: Cache Python dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          pip freeze > requirements.txt  # ðŸ”¹ Guardar las versiones exactas

      # ðŸ”¹ Nuevo paso para extraer el primer pÃ¡rrafo si es una URL
      - name: Extract text from URL or use input
        run: |
          python -c "
          import sys
          from newspaper import Article
          text = '${{ github.event.inputs.text }}'
          if text.startswith('http://') or text.startswith('https://'):
              try:
                  article = Article(text)
                  article.download()
                  article.parse()
                  content = article.text
                  first_paragraph = content.split('\n\n')[0].strip() if content else 'No content found'
                  text = first_paragraph
              except Exception as e:
                  text = f'Error extracting content: {str(e)}'
          with open('input.txt', 'w', encoding='utf-8') as f:
              f.write(text)
          "

      - name: Analyze text
        id: analyze
        env:
          CUDA_VISIBLE_DEVICES: "-1"
        run: |
          python ai_model.py input.txt > output.txt
          {
            echo "result<<EOF"
            cat output.txt
            echo "EOF"
          } >> "$GITHUB_OUTPUT"
          
      - name: Mostrar salida
        run: cat output.txt

      - name: Mostrar entrada
        run: cat input.txt
          
      - name: Upload result
        uses: actions/upload-artifact@v4
        with:
          name: analysis-result
          path: output.txt
