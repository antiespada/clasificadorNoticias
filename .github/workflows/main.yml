name: Process Text
on:
  workflow_dispatch:
    inputs:
      text:
        description: 'Text to analyze (URL or plain text)'
        required: true
        type: string

jobs:
  analyze:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      # Build the Docker image locally if not cached
      - name: Build Docker image
        run: |
          docker build -t text-processor:latest .

      # Run Docker container with mounted workspace
      - name: Run Docker container
        run: docker run --rm -v ${{ github.workspace }}:/app text-processor:latest

      - name: Extract text from URL or use input
        run: |
          python -c "
          import sys
          import requests
          from bs4 import BeautifulSoup
          text = '''${{ github.event.inputs.text }}'''
          if text.startswith('http://') or text.startswith('https://'):
              try:
                  response = requests.get(text, timeout=10)
                  soup = BeautifulSoup(response.text, 'html.parser')
                  paragraphs = soup.find_all('p')
                  first_paragraph = paragraphs[0].get_text().strip() if paragraphs else 'No paragraphs found'
                  text = first_paragraph
              except Exception as e:
                  text = f'Error extracting content: {str(e)}'
          with open('input.txt', 'w', encoding='utf-8') as f:
              f.write(text)
          "

      - name: Show output
        run: cat output.txt

      - name: Show input
        run: cat input.txt

      - name: Upload result
        uses: actions/upload-artifact@v4
        with:
          name: analysis-result
          path: output.txt
